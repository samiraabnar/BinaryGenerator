{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTM_cell(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.random_state = np.random.RandomState(284783)\n",
    "        self.output_dim = 10\n",
    "        self.outer_output_dim = 1\n",
    "        self.input_dim = self.outer_output_dim\n",
    "        self.layer_id = \"0\"\n",
    "        self.learning_rate = 0.1\n",
    "        \n",
    "        self.initialize_params()\n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "    def initialize_params(self):\n",
    "        U_input = np.asarray(\n",
    "            self.random_state.normal(-np.sqrt(6.0 / (self.input_dim + self.output_dim)),\n",
    "                                     np.sqrt(6.0 / (self.input_dim + self.output_dim)),\n",
    "                                     (self.output_dim, self.input_dim))\n",
    "            , dtype=theano.config.floatX)\n",
    "\n",
    "        U_forget = np.asarray(\n",
    "            self.random_state.normal(-np.sqrt(6.0 / (self.input_dim + self.output_dim)),\n",
    "                                     np.sqrt(6.0 / (self.input_dim + self.output_dim)),\n",
    "                                     (self.output_dim, self.input_dim))\n",
    "            , dtype=theano.config.floatX)\n",
    "\n",
    "        U_output = np.asarray(\n",
    "            self.random_state.normal(-np.sqrt(6.0 / (self.input_dim + self.output_dim)),\n",
    "                                     np.sqrt(6.0 / (self.input_dim + self.output_dim)),\n",
    "                                     (self.output_dim, self.input_dim))\n",
    "            , dtype=theano.config.floatX)\n",
    "\n",
    "        W_input = np.asarray(\n",
    "            self.random_state.normal(-np.sqrt(6.0 / (self.output_dim + self.output_dim)),\n",
    "                                     np.sqrt(6.0 / (self.output_dim + self.output_dim)),\n",
    "                                     (self.output_dim, self.output_dim))\n",
    "            , dtype=theano.config.floatX)\n",
    "\n",
    "        W_forget = np.asarray(\n",
    "            self.random_state.normal(-np.sqrt(6.0 / (self.output_dim + self.output_dim)),\n",
    "                                     np.sqrt(6.0 / (self.output_dim + self.output_dim)),\n",
    "                                     (self.output_dim, self.output_dim))\n",
    "            , dtype=theano.config.floatX)\n",
    "\n",
    "        W_output = np.asarray(\n",
    "            self.random_state.normal(-np.sqrt(6.0 / (self.output_dim + self.output_dim)),\n",
    "                                     np.sqrt(6.0 / (self.output_dim + self.output_dim)),\n",
    "                                     (self.output_dim, self.output_dim))\n",
    "            , dtype=theano.config.floatX)\n",
    "\n",
    "        U = np.asarray(\n",
    "            self.random_state.normal(-np.sqrt(6.0 / (self.input_dim + self.output_dim)),\n",
    "                                     np.sqrt(6.0 / (self.input_dim + self.output_dim)),\n",
    "                                     (self.output_dim, self.input_dim))\n",
    "            , dtype=theano.config.floatX)\n",
    "\n",
    "        W = np.asarray(\n",
    "            self.random_state.normal(-np.sqrt(6.0 / (self.output_dim + self.output_dim)),\n",
    "                                     np.sqrt(6.0 / (self.output_dim + self.output_dim)),\n",
    "                                     (self.output_dim, self.output_dim))\n",
    "            , dtype=theano.config.floatX)\n",
    "\n",
    "        bias_input = np.zeros(self.output_dim, dtype=theano.config.floatX)\n",
    "        bias_forget = np.zeros(self.output_dim, dtype=theano.config.floatX)\n",
    "        bias_output = np.zeros(self.output_dim, dtype=theano.config.floatX)\n",
    "        bias = np.zeros(self.output_dim, dtype=theano.config.floatX)\n",
    "\n",
    "        \n",
    "        self.W = theano.shared(value=W, name=\"W\" + self.layer_id, borrow=\"True\")\n",
    "        self.U = theano.shared(value=U, name=\"U\" + self.layer_id, borrow=\"True\")\n",
    "        self.bias = theano.shared(value=bias, name=\"bias\", borrow=\"True\")\n",
    "\n",
    "        self.W_input = theano.shared(value=W_input, name=\"W_input\" + self.layer_id, borrow=\"True\")\n",
    "        self.U_input = theano.shared(value=U_input, name=\"U_input\" + self.layer_id, borrow=\"True\")\n",
    "        self.bias_input = theano.shared(value=bias_input, name=\"bias_input\" + self.layer_id, borrow=\"True\")\n",
    "\n",
    "        self.W_output = theano.shared(value=W_output, name=\"W_output\" + self.layer_id, borrow=\"True\")\n",
    "        self.U_output = theano.shared(value=U_output, name=\"U_output\" + self.layer_id, borrow=\"True\")\n",
    "        self.bias_output = theano.shared(value=bias_output, name=\"bias_output\" + self.layer_id, borrow=\"True\")\n",
    "\n",
    "        self.W_forget = theano.shared(value=W_forget, name=\"W_forget\" + self.layer_id, borrow=\"True\")\n",
    "        self.U_forget = theano.shared(value=U_forget, name=\"U_forget\" + self.layer_id, borrow=\"True\")\n",
    "        self.bias_forget = theano.shared(value=bias_forget, name=\"bias_forget\" + self.layer_id, borrow=\"True\")\n",
    "        self.W = theano.shared(value=W, name=\"W\" + self.layer_id, borrow=\"True\")\n",
    "        self.U = theano.shared(value=U, name=\"U\" + self.layer_id, borrow=\"True\")\n",
    "        self.bias = theano.shared(value=bias, name=\"bias\", borrow=\"True\")\n",
    "        O_w = np.asarray(\n",
    "            self.random_state.normal(-np.sqrt(6.0 / (self.output_dim + self.output_dim)),\n",
    "                                      np.sqrt(6.0 / (self.output_dim + self.output_dim)),\n",
    "                                      (self.outer_output_dim,self.output_dim))\n",
    "            , dtype=theano.config.floatX)\n",
    "\n",
    "        O_bias = np.zeros(self.outer_output_dim, dtype=theano.config.floatX)\n",
    "\n",
    "        self.O_w = theano.shared(value=O_w, name=\"O_w\"+self.layer_id, borrow=\"True\")\n",
    "        self.O_bias = theano.shared(value=O_bias, name=\"O_bias\"+self.layer_id, borrow=\"True\")\n",
    "\n",
    "        self.params = [self.U_input, self.U_forget, self.U_output, self.W_input, self.W_forget, self.W_output,\n",
    "                       self.bias_input, self.bias_forget, self.bias_output, self.U, self.W, self.bias,\n",
    "                       ]\n",
    "\n",
    "        self.output_params = [self.O_w,self.O_bias]\n",
    "    \n",
    "\n",
    "    \n",
    "    def buil_model(self):\n",
    "        def forward_step(x_t,prev_state,prev_content):\n",
    "            input_gate = T.nnet.hard_sigmoid(T.dot(self.U_input,x_t) + T.dot(self.W_input,prev_state) + self.bias_input)\n",
    "            forget_gate = T.nnet.hard_sigmoid(T.dot(self.U_forget,x_t) + T.dot(self.W_forget,prev_state) + self.bias_forget)\n",
    "            output_gate = T.nnet.hard_sigmoid(T.dot(self.U_output,x_t) + T.dot(self.W_output,prev_state) + self.bias_output)\n",
    "\n",
    "            stabialized_input = T.tanh(T.dot(self.U,x_t) + T.dot(self.W,prev_state) + self.bias)\n",
    "            c = forget_gate * prev_content + input_gate * stabialized_input\n",
    "            s = output_gate * T.tanh(c)\n",
    "\n",
    "            o = T.nnet.sigmoid(T.dot(self.O_w,s) + self.O_bias)\n",
    "\n",
    "            return [o,s,c]\n",
    "        \n",
    "        params = self.params + self.output_params\n",
    "        \n",
    "        initial_hidden_state = T.matrix('H')\n",
    "        y = T.matrix('Y')\n",
    "        x = T.matrix('X')    \n",
    "        \n",
    "        [output,states,mem_content],updates = theano.scan(forward_step, sequences=x,\n",
    "                                                          outputs_info=[None, \n",
    "                                                                        dict(initial=T.zeros(self.output_dim,dtype=theano.config.floatX)), \n",
    "                                                                        dict(initial=T.zeros(self.output_dim,dtype=theano.config.floatX))])\n",
    "        \n",
    "        self.forward_step = theano.function([x],[output])\n",
    "        \n",
    "       \n",
    "        cost = T.argmax(abs( y - np.round(output)))\n",
    "        grads = theano.grad(cost,params)\n",
    "        updates = [ (p,p - self.learning_rate*g*p) for p,g in zip(params,grads)]\n",
    "        self.training_step = theano.function([x,y],[output], updates=updates)\n",
    "        \n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_cell = LSTM_cell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in np.arange(100):\n",
    "    H = np.random.binomial(1, np.random.random(), size=10)\n",
    "    Y = [[h] for h in H]\n",
    "    X = [[0] for y in Y]\n",
    "    [outputs] = lstm_cell.training_step(X,Y)\n",
    "    print(outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_cell.buil_model()\n",
    "print(np.argmax(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(outputs)\n",
    "print(np.argmax(outputs,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
